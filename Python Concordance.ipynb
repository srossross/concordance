{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup \n",
    "import re\n",
    "\n",
    "data = \"\"\"\n",
    "A \"concordance\" is an alphabetical list of the words present in a text with a count of how\n",
    "often each word appears and citations of where each word appears in the text (e.g., page\n",
    "number). Write a program -- in the programming language of your choice -- that will\n",
    "generate a concordance of an arbitrary text document written in English: the text can be\n",
    "read from stdin, and the program should output the concordance to stdout or a file. For\n",
    "each word, it should print the count and the sorted list of citations, in this case the\n",
    "zero-indexed sentence number in which that word occurs. You may assume that the input\n",
    "contains only spaces, newlines, standard English letters, and standard English punctuation\n",
    "marks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "invalid_chars = re.compile(\"[^\\w'.]\")\n",
    "\n",
    "def split_into_words_initial(input, sections='. '):\n",
    "    \"\"\"\n",
    "    OK, starting here. The first thing that comes to mind is \n",
    "    it may be necessary to use an existing library to split into word eg special characters \n",
    "    root words ect...\n",
    "    \n",
    "    This is my first pass so I will do a string.split\n",
    "    The result of this should be a list of lists [ [word, ...], ... ]\n",
    "    The outer list will contain the 'sections' and each section will contain a list of words\n",
    "    \n",
    "    :param sections: How to split the text into sections. '. ' should define the end of a sentence\n",
    "    \n",
    "    Note: that this will split up words like 'zero-indexed' into 'zero' and 'indexed'\n",
    "    \"\"\"\n",
    "    \n",
    "    # The first thing that I see is that there is a lot of puntuation,\n",
    "    for section in input.lower().split(sections):\n",
    "        # I would nltk.tokenize from the nltk library if this were not a test\n",
    "        # but I this is fine\n",
    "        yield invalid_chars.sub(' ', section).split()\n",
    "\n",
    "# Test to see if this is working correctly\n",
    "# list(split_into_words_initial(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def concordance(input):\n",
    "    \"\"\"\n",
    "    Count of how often each word appears and citations of where each word appears in the text\n",
    "    \n",
    "    :param input: a text\n",
    "    :returns: a data structure of {word: [section_num, ... ] }\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initial thought is that result can be a dict of {word: {section: count, ...}, ... }\n",
    "    # I Then modified this to a less compact form because the output requires printing all of the \n",
    "    # and list of sentence numbers\n",
    "    # So the final data structure is {word: [section_num, ... ] }\n",
    "    result = {}\n",
    "    \n",
    "    # Loop over the sections\n",
    "    for section_num, section in enumerate(split_into_words_initial(input)):\n",
    "        for word in section:\n",
    "            result.setdefault(word, []).append(section_num)\n",
    "            \n",
    "\n",
    "    return result\n",
    "        \n",
    "concordance_result = concordance(data)\n",
    "\n",
    "# print(concordance_result)\n",
    "# OK, this looks right lets store this an format this for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a               {6:0,0,0,1,1,1}\n",
      "alphabetical    {1:0}\n",
      "an              {2:0,1}\n",
      "and             {4:0,1,2,3}\n",
      "appears         {2:0,0}\n",
      "arbitrary       {1:1}\n",
      "assume          {1:3}\n",
      "be              {1:1}\n",
      "can             {1:1}\n",
      "case            {1:2}\n",
      "choice          {1:1}\n",
      "citations       {2:0,2}\n",
      "concordance     {3:0,1,1}\n",
      "contains        {1:3}\n",
      "count           {2:0,2}\n",
      "document        {1:1}\n",
      "e.g.            {1:0}\n",
      "each            {3:0,0,2}\n",
      "english         {3:1,3,3}\n",
      "file            {1:1}\n",
      "for             {1:2}\n",
      "from            {1:1}\n",
      "generate        {1:1}\n",
      "how             {1:0}\n",
      "in              {6:0,0,1,1,2,2}\n",
      "indexed         {1:2}\n",
      "input           {1:3}\n",
      "is              {1:0}\n",
      "it              {1:2}\n",
      "language        {1:1}\n",
      "letters         {1:3}\n",
      "list            {2:0,2}\n",
      "marks.          {1:3}\n",
      "may             {1:3}\n",
      "newlines        {1:3}\n",
      "number          {2:0,2}\n",
      "occurs          {1:2}\n",
      "of              {6:0,0,0,1,1,2}\n",
      "often           {1:0}\n",
      "only            {1:3}\n",
      "or              {1:1}\n",
      "output          {1:1}\n",
      "page            {1:0}\n",
      "present         {1:0}\n",
      "print           {1:2}\n",
      "program         {2:1,1}\n",
      "programming     {1:1}\n",
      "punctuation     {1:3}\n",
      "read            {1:1}\n",
      "sentence        {1:2}\n",
      "should          {2:1,2}\n",
      "sorted          {1:2}\n",
      "spaces          {1:3}\n",
      "standard        {2:3,3}\n",
      "stdin           {1:1}\n",
      "stdout          {1:1}\n",
      "text            {4:0,0,1,1}\n",
      "that            {3:1,2,3}\n",
      "the             {10:0,0,1,1,1,1,2,2,2,3}\n",
      "this            {1:2}\n",
      "to              {1:1}\n",
      "where           {1:0}\n",
      "which           {1:2}\n",
      "will            {1:1}\n",
      "with            {1:0}\n",
      "word            {4:0,0,2,2}\n",
      "words           {1:0}\n",
      "write           {1:1}\n",
      "written         {1:1}\n",
      "you             {1:3}\n",
      "your            {1:1}\n",
      "zero            {1:2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def printer(result):\n",
    "    \"\"\"\n",
    "    Print the result of the concordance function to stdout. \n",
    "    \n",
    "    :param result: result ofconcordance function. This is not strictly enforced\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop over alphibetical words\n",
    "    for word in sorted(result):\n",
    "        concordance = result[word]\n",
    "        total_occurrences = len(concordance)\n",
    "        sentence_numbers = \",\".join([str(i) for i in concordance])\n",
    "        print(\"{:15} {{{}:{}}}\".format(word, total_occurrences, sentence_numbers))\n",
    "    \n",
    "\n",
    "printer(concordance_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
